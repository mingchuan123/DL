{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108155748>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \n",
    "    return np.array(x/255.0)\n",
    "\n",
    "\n",
    "def one_hot_encode(x):\n",
    "\n",
    "    encoding = np.zeros((len(x),10))\n",
    "    encoding[np.arange(len(x)),x] = 1\n",
    "    return encoding\n",
    "\n",
    "\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)\n",
    "\n",
    "\n",
    "import pickle\n",
    "#import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib import rnn\n",
    "tf.reset_default_graph()\n",
    "\n",
    "epoches = 10\n",
    "classes = 10\n",
    "batch_size = 128\n",
    "hidden_num = 8\n",
    "n_batches = 5\n",
    "\n",
    "#x = tf.placeholder(tf.float32,[None,32,32,3])\n",
    "x = tf.placeholder(tf.float32,[None,32,32,3])\n",
    "y = tf.placeholder(tf.float32,[None,classes])\n",
    "\n",
    "#print(x)\n",
    "#y = tf.placeholder(tf.float32,[None,classes])\n",
    "#print(y)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def conv(x,W,strides):\n",
    "    return tf.nn.conv2d(x,W,strides,padding = 'SAME')\n",
    "\n",
    "def maxpool(x,ksize,strides):\n",
    "    return tf.nn.max_pool(x,ksize,strides,padding='SAME' )\n",
    "\n",
    "def convolutional_neural_network(x,keep_prob):\n",
    "    weights_conv_1 = tf.Variable(tf.truncated_normal([2,2,3,8], stddev = 0.1))\n",
    "    weights_conv_2 = tf.Variable(tf.truncated_normal([3,3,8,16], stddev = 0.1))\n",
    "    weights_conv_3 = tf.Variable(tf.truncated_normal([4,4,16,32], stddev = 0.1))\n",
    "    weights_full = tf.Variable(tf.truncated_normal([4*4*32, 1024], stddev = 0.1))\n",
    "    #weights_full = tf.Variable(tf.truncated_normal([hidden_num, 1024], stddev = 0.1))\n",
    "    weights_out = tf.Variable(tf.random_normal([1024,classes], stddev = 0.1))\n",
    "    \n",
    "    bias_conv_1 = tf.Variable(tf.zeros([8]))\n",
    "    bias_conv_2 = tf.Variable(tf.zeros([16]))\n",
    "    bias_conv_3 = tf.Variable(tf.zeros([32]))\n",
    "    bias_full = tf.Variable(tf.zeros([1024]))\n",
    "    bias_out = tf.Variable(tf.zeros([classes]))\n",
    "\n",
    "    x = tf.reshape(x, shape = [-1,32,32,3])\n",
    "    conv_1 = conv(x,weights_conv_1,[1,1,1,1])\n",
    "    conv_1 = maxpool(conv_1,[1,2,2,1],[1,2,2,1])\n",
    "    #print(conv_1.shape)\n",
    "\n",
    "    conv_2 = conv(conv_1,weights_conv_2,[1,1,1,1])\n",
    "    conv_2 = maxpool(conv_2,[1,2,2,1],[1,2,2,1])\n",
    "    #print(conv_2.shape)\n",
    "    \n",
    "    conv_3 = conv(conv_2,weights_conv_3,[1,1,1,1])\n",
    "    conv_3 = maxpool(conv_3,[1,2,2,1],[1,2,2,1])\n",
    "    print(conv_3)\n",
    "    \n",
    "    \n",
    "    dim = conv_3.get_shape().as_list()\n",
    "    #print(dim)\n",
    "    conv_f = tf.reshape(conv_3,[-1,dim[1]*dim[2]*dim[3]])\n",
    "    #print(conv_f.shape)\n",
    "    conv_f = tf.nn.relu(tf.matmul(conv_f,weights_full) + bias_full)\n",
    "    conv_f = tf.nn.relu(conv_f)\n",
    "    conv_f = tf.nn.dropout(conv_f,keep_prob)\n",
    "    #print(conv_f.shape)\n",
    "\n",
    "    conv_o = tf.nn.relu(tf.matmul(conv_f,weights_out) + bias_out)\n",
    "    conv_o = tf.nn.dropout(conv_o,keep_prob)\n",
    "    #print(conv_o.shape)\n",
    "    return conv_o,conv_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_x = tf.placeholder(tf.float32,[None,4,4,32])\n",
    "r_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "r_y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "\n",
    "def recurrent_neural_network(r_x,r_keep_prob):    \n",
    "    dim = r_x.get_shape().as_list()\n",
    "    print(dim)\n",
    "    recurrent_input = tf.reshape(r_x,[-1,dim[1],dim[2]*dim[3]])\n",
    "    #recurrent_input = tf.reshape(x,[128,4,128])\n",
    "    \n",
    "    weights_full = tf.Variable(tf.truncated_normal([hidden_num, 1024], stddev = 0.1))\n",
    "    bias_full = tf.Variable(tf.zeros([1024]))\n",
    "\n",
    "    weights_out = tf.Variable(tf.random_normal([1024,classes], stddev = 0.1))\n",
    "    bias_out = tf.Variable(tf.zeros([classes]))\n",
    "    \n",
    "    data = tf.transpose(recurrent_input,[0,2,1])\n",
    "    cell = rnn.LSTMCell(hidden_num,state_is_tuple = True)\n",
    "    cell = rnn.DropoutWrapper(cell,r_keep_prob)\n",
    "    value, state = tf.nn.dynamic_rnn(cell,data,dtype = tf.float32)\n",
    "    value = tf.transpose(value,[1,0,2])\n",
    "    last_val = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "    \n",
    "    recc_f = tf.nn.relu(tf.matmul(last_val,weights_full) + bias_full)\n",
    "    \n",
    "    recc_o = tf.nn.relu(tf.matmul(recc_f,weights_out) + bias_out)\n",
    "\n",
    "    return recc_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 32), dtype=float32)\n",
      "Epoch 0 complete out of 10 loss: 659.474973083\n",
      "Accuracy: 0.5312\n",
      "Epoch 1 complete out of 10 loss: 527.733355761\n",
      "Accuracy: 0.583\n",
      "Epoch 2 complete out of 10 loss: 479.500790536\n",
      "Accuracy: 0.6056\n",
      "Epoch 3 complete out of 10 loss: 450.010113895\n",
      "Accuracy: 0.6234\n",
      "Epoch 4 complete out of 10 loss: 422.321885347\n",
      "Accuracy: 0.6398\n",
      "Epoch 5 complete out of 10 loss: 397.913194478\n",
      "Accuracy: 0.6404\n",
      "Epoch 6 complete out of 10 loss: 374.683700413\n",
      "Accuracy: 0.6424\n",
      "Epoch 7 complete out of 10 loss: 358.992618054\n",
      "Accuracy: 0.6514\n",
      "Epoch 8 complete out of 10 loss: 339.265804768\n",
      "Accuracy: 0.651\n",
      "Epoch 9 complete out of 10 loss: 318.713316381\n",
      "Accuracy: 0.6556\n",
      "Accuracy: 0.6463\n"
     ]
    }
   ],
   "source": [
    "def train(x,keep_prob):\n",
    "    prediction,features = convolutional_neural_network(x,keep_prob)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction,labels = y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    featureset = []\n",
    "    #featureset_valid = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        tf.set_random_seed(1000)\n",
    "\n",
    "        for epoch in range(epoches):\n",
    "            loss = 0\n",
    "            n_batches = 5\n",
    "            #for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "            #for batch_i in range(1, n_batches+1):\n",
    "\n",
    "            for batch_i in range(1, n_batches+1):\n",
    "                for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                    #epoch_x = epoch_x.reshape((batch_size,chunks,chunk_size))\n",
    "                    _,c = sess.run([optimizer,cost],feed_dict = {x: batch_features, y: batch_labels, keep_prob: 0.9})\n",
    "                    features_n = features.eval({x: batch_features, y: batch_labels, keep_prob: 0.9})\n",
    "                    \n",
    "                    features_n = np.array(features_n,dtype=np.float32)\n",
    "                    \n",
    "                    featureset.append(features_n)\n",
    "                    loss += c\n",
    "            print('Epoch',epoch,'complete out of',epoches,'loss:',loss)\n",
    "            #print(prediction.shape)\n",
    "            features_valid = features.eval({x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "            \n",
    "            correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "            print('Accuracy:',accuracy.eval({x: valid_features, y: valid_labels, keep_prob: 1.0}))\n",
    "            \n",
    "            \n",
    "\n",
    "        print('Accuracy:',accuracy.eval({x: test_features, y: test_labels, keep_prob: 1.0}))\n",
    "        #featureset = np.array(featureset[-5:])\n",
    "        return featureset,features_valid\n",
    "\n",
    "        \n",
    "c_out,c_valid = train(x,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 4, 4, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaomingchuan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete out of 10 loss: 803.550757885\n",
      "Accuracy: 0.1642\n",
      "Epoch 1 complete out of 10 loss: 804.824974537\n",
      "Accuracy: 0.1454\n",
      "Epoch 2 complete out of 10 loss: 801.055309057\n",
      "Accuracy: 0.1478\n",
      "Epoch 3 complete out of 10 loss: 799.746410608\n",
      "Accuracy: 0.1464\n",
      "Epoch 4 complete out of 10 loss: 797.562066078\n",
      "Accuracy: 0.144\n",
      "Epoch 5 complete out of 10 loss: 795.892113924\n",
      "Accuracy: 0.151\n",
      "Epoch 6 complete out of 10 loss: 794.068750858\n",
      "Accuracy: 0.158\n",
      "Epoch 7 complete out of 10 loss: 785.784734964\n",
      "Accuracy: 0.182\n",
      "Epoch 8 complete out of 10 loss: 782.8654809\n",
      "Accuracy: 0.183\n",
      "Epoch 9 complete out of 10 loss: 779.712507248\n",
      "Accuracy: 0.1812\n",
      "Epoch 10 complete out of 10 loss: 775.076630831\n",
      "Accuracy: 0.1846\n",
      "Epoch 11 complete out of 10 loss: 770.954980373\n",
      "Accuracy: 0.1776\n",
      "Epoch 12 complete out of 10 loss: 769.149760962\n",
      "Accuracy: 0.175\n",
      "Epoch 13 complete out of 10 loss: 767.66845417\n",
      "Accuracy: 0.1732\n"
     ]
    }
   ],
   "source": [
    "def r_train(data,valid_data,r_x,r_keep_prob):\n",
    "    #data = train(x,keep_prob)\n",
    "    n_batches = 5\n",
    "    r_epoches = 15\n",
    "    r_prediction = recurrent_neural_network(r_x,r_keep_prob)\n",
    "    \n",
    "    r_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = r_prediction,labels = r_y))\n",
    "    r_optimizer = tf.train.AdamOptimizer().minimize(r_cost)\n",
    "    \n",
    "    with tf.Session() as r_sess:\n",
    "        r_sess.run(tf.global_variables_initializer())\n",
    "        #sess.run(data.eval())\n",
    "        #data = sess.run(data)\n",
    "        for epoch in range(r_epoches):\n",
    "            loss = 0\n",
    "            i = 0\n",
    "            #for batch_i in range(1, n_batches + 1):\n",
    "            for batch_i in range(1, n_batches+1):\n",
    "                for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "\n",
    "                    data_in = data[i]\n",
    "                    _,c = r_sess.run([r_optimizer,r_cost],feed_dict = {r_x: data_in, r_y: batch_labels, r_keep_prob: 0.9})\n",
    "                    loss += c\n",
    "                    i += 1\n",
    "    \n",
    "            print('Epoch',epoch,'complete out of',epoches,'loss:',loss)\n",
    "            #print(r_prediction.shape)\n",
    "            correct = tf.equal(tf.argmax(r_prediction,1),tf.argmax(r_y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "            print('Accuracy:',accuracy.eval({r_x: valid_data, r_y: valid_labels, r_keep_prob: 1.0}))    \n",
    "        \n",
    "        \n",
    "r_train(c_out,c_valid,r_x,r_keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train(x,keep_prob)\n",
    "print(data)\n",
    "#r_x = tf.placeholder(tf.float32)\n",
    "#print(r_x)\n",
    "#r_keep_prob = tf.placeholder(tf.float32)\n",
    "#print(r_keep_prob)\n",
    "#r_y = tf.placeholder(tf.float32,[None,10])\n",
    "n_batches = 5\n",
    "r_epoches = 5\n",
    "prediction = recurrent_neural_network(r_x,keep_prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction,labels = y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(data.eval())\n",
    "    #data = sess.run(data)\n",
    "    for epoch in range(r_epoches):\n",
    "        loss = 0\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                data_in = data[batch_i]\n",
    "                #TensorArr = tf.TensorArray(tf.float32, 1, dynamic_size=True, infer_shape=False)\n",
    "                #data_in = TensorArr.unstack(data[batch_i])\n",
    "                #data[batch_i].set_shape([len(batch_labels),4,4,32])\n",
    "                #data_in = tf.unstack(data[batch_i])\n",
    "                #data_in.eval()\n",
    "                #data_in = tf.TensorArray.read(index = batch_i,name = data)\n",
    "                #epoch_x = epoch_x.reshape((batch_size,chunks,chunk_size))\n",
    "                #data_in = tf.unstack(data[batch_i],axis=0)\n",
    "                data_in = sess.run(data_in)\n",
    "                _,c = sess.run([optimizer,cost],feed_dict = {r_x: data_in, r_y: batch_labels, r_keep_prob: 0.9})\n",
    "                loss += c\n",
    "    \n",
    "        print('Epoch',epoch,'complete out of',epoches,'loss:',loss)\n",
    "        print(prediction.shape)\n",
    "        correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('Accuracy:',accuracy.eval({x: valid_features, y: valid_labels, keep_prob: 1.0}))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
